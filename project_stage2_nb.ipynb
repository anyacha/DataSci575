{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy for working with Arrays\n",
    "import numpy as np\n",
    "# Pandas for working with data tables\n",
    "import pandas as pd\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "# Module for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Module for pretty plotting\n",
    "# import seaborn as sns\n",
    "# Module for linear regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "# the bayes stuff\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### load data from csv files\n",
    "water_values = pd.read_csv('./data/train_set_values.csv')\n",
    "water_labels = pd.read_csv('./data/train_set_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list categorical features to be turned into dummy variables:\n",
    "cat_features = ['region_code', 'district_code', 'basin', 'region', 'public_meeting', \\\n",
    "                'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', \\\n",
    "                'management', 'payment', 'water_quality', 'quantity', \\\n",
    "                'source', 'waterpoint_type', 'date_recorded', 'recorded_by', 'funder', 'installer', \\\n",
    "               'lga', 'ward', 'scheme_name', 'management_group', 'wpt_name', 'subvillage', \\\n",
    "               'payment_type', 'quality_group', 'quantity_group', 'source_class', 'source_type', 'waterpoint_type_group']\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "water_cat = water_values[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "#water_num = water_values[list(set(water_values.columns) - set(cat_features))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare test data for model prediction\n",
    "test = pd.read_csv('./test_set_values.csv')\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "test_cat = test[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "#test_num = test[list(set(test.columns) - set(cat_features))]\n",
    "\n",
    "# replace 0s with NaN\n",
    "#for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "#    test_num.loc[:,col].replace(0, np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine training and test data, so that when dummy variables are created, all categories from both datasets are included\n",
    "# if this is not done, clf.predict will fail because test set will have different number of features \n",
    "all_cat = pd.concat([water_cat, test_cat])\n",
    "\n",
    "#all_num = pd.concat([water_num, test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert status labels to numeric\n",
    "water_labels['status_group'] = water_labels.status_group.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing steps\n",
    "# encode labels to floats\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# make dummy variables\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown = 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in cat_features:\n",
    "    all_cat.loc[:,col] = le.fit_transform(all_cat.loc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cat = enc.fit_transform(all_cat[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#water_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute numeric data\n",
    "#imp = preprocessing.Imputer(missing_values='NaN', strategy='most_frequent', axis=0, verbose=0, copy=True)\n",
    "#all_num = imp.fit_transform(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize numeric variables\n",
    "# all_num = preprocessing.scale(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split back into training and test sets\n",
    "water_cat = all_cat[:59400,:]\n",
    "water_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_cat = all_cat[59400:,:]\n",
    "test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#water_num = all_num[:59400,:]\n",
    "#water_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_num = all_num[59400:,:]\n",
    "#test_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to sparse matrix\n",
    "#water_num = csr_matrix(water_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate \n",
    "#X = hstack([water_cat, water_num])#.toarray()\n",
    "X = water_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten label column into a 1-D array called y\n",
    "y = np.ravel(water_labels['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = X[:10000,:]\n",
    "X2 = X[10001:20000,:]\n",
    "X3 = X[20001:30000,:]\n",
    "X4 = X[30001:40000,:]\n",
    "X5 = X[40001:50000,:]\n",
    "X6 = X[50001:,:]\n",
    "\n",
    "Xlist = [X1, X2, X3, X4, X5, X6]\n",
    "\n",
    "y1 = y[:10000]\n",
    "y2 = y[10001:20000]\n",
    "y3 = y[20001:30000]\n",
    "y4 = y[30001:40000]\n",
    "y5 = y[40001:50000]\n",
    "y6 = y[50001:]\n",
    "\n",
    "ylist = [y1, y2, y3, y4, y5, y6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Because X is too large to fit into memory as a dense array (req'd by NB), break into chunks and partially fit each in a loop:\n",
    "\n",
    "for x, y in zip(Xlist, ylist):\n",
    "    x = x.toarray()\n",
    "    print type(x)\n",
    "    clf.partial_fit(x, y, classes = [0,1,2])\n",
    "    x = '' # release memory\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the accuracy on the training set\n",
    "X1 = X1.toarray()\n",
    "print clf.score(X1, y1)\n",
    "X1=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2 = X2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create train, test sets for X,Y to cross-validate, k=1 (just to verify above cross-val)\n",
    "xtrain, xtest, ytrain, ytest = \\\n",
    "cross_validation.train_test_split(X2, y2, test_size=0.2, random_state=101)\n",
    "\n",
    "# verify shapes\n",
    "print xtrain.shape, ytrain.shape\n",
    "print xtest.shape, ytest.shape\n",
    "\n",
    "# predict labels for test set\n",
    "yhat = clf.predict(xtest)\n",
    "\n",
    "# calculate accuracy\n",
    "np.mean(yhat == ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2=''\n",
    "X1=''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
