{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### same as myProject_stage2_Knn, only including a few less features\n",
    "### took Brett's LR code from branch 'LogisticRegression'\n",
    "### adding my parts with marker $accode\n",
    "### tried Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy for working with Arrays\n",
    "import numpy as np\n",
    "# Pandas for working with data tables\n",
    "import pandas as pd\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "# Module for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Module for pretty plotting\n",
    "# import seaborn as sns\n",
    "# Module for linear regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### load data from csv files\n",
    "water_values = pd.read_csv('./data/train_set_values.csv')\n",
    "water_labels = pd.read_csv('./data/train_set_labels.csv')\n",
    "\n",
    "#water_values.drop(['wpt_name', 'subvillage'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list categorical features to be turned into dummy variables:\n",
    "##$accodechange excluding wpt_name\n",
    "\"\"\"\n",
    "cat_features = ['region_code', 'district_code', 'basin', 'region', 'public_meeting', \\\n",
    "                'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', \\\n",
    "                'management', 'payment', 'water_quality', 'quantity', \\\n",
    "                'source', 'waterpoint_type', 'date_recorded', 'recorded_by', 'funder', 'installer', \\\n",
    "               'lga', 'ward', 'scheme_name', 'management_group', 'wpt_name', 'subvillage', \\\n",
    "               'payment_type', 'quality_group', 'quantity_group', 'source_class', 'source_type', 'waterpoint_type_group']\n",
    "\n",
    "\"\"\"\n",
    "cat_features = ['region_code', 'district_code', 'basin', 'region', 'public_meeting', \\\n",
    "                'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', \\\n",
    "                'management', 'payment', 'water_quality', 'quantity', \\\n",
    "                'source', 'waterpoint_type', 'date_recorded', 'recorded_by', 'funder', 'installer', \\\n",
    "               'lga', 'ward', 'scheme_name', 'management_group', 'subvillage', \\\n",
    "               'payment_type', 'quality_group', 'quantity_group', 'source_class', 'source_type', 'waterpoint_type_group']\n",
    "\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "water_cat = water_values[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "water_num = water_values[list(set(water_values.columns) - set(cat_features))]\n",
    "water_num=water_num.ix[:,water_num.columns!='wpt_name'] ##$accodechange excluding wpt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare test data for model prediction\n",
    "test = pd.read_csv('data/test_set_values.csv')\n",
    "\n",
    "#test['status_group'] = np.random.choice(range(1, 3), test.shape[0])\n",
    "#test.drop(['wpt_name', 'subvillage'], axis=1, inplace=True)\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "test_cat = test[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "test_num = test[list(set(test.columns) - set(cat_features))]\n",
    "test_num=test_num.ix[:,test_num.columns!='wpt_name']  ##$accodechange excluding wpt_name\n",
    "\n",
    "# replace 0s with NaN\n",
    "for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "    test_num.loc[:,col].replace(0, np.nan, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cat = pd.concat([water_cat, test_cat])\n",
    "all_num = pd.concat([water_num, test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert status labels to numeric\n",
    "water_labels['status_group'] = water_labels.status_group.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace 0s with NaN\n",
    "for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "    all_num.loc[:,col].replace(0, np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing steps\n",
    "# encode labels to floats\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# make dummy variables\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in cat_features:\n",
    "    all_cat.loc[:,col] = le.fit_transform(all_cat.loc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<74250x31662 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 2301750 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cat = enc.fit_transform(all_cat[cat_features])\n",
    "all_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'gps_height', u'longitude', u'latitude', u'amount_tsh', u'num_private',\n",
       "       u'construction_year', u'id', u'population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute data\n",
    "imp = preprocessing.Imputer(missing_values='NaN', strategy='most_frequent', axis=0, verbose=0, copy=True)\n",
    "all_num = imp.fit_transform(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize numeric variables\n",
    "all_num = preprocessing.scale(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 31662)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_cat = all_cat[:59400,:]\n",
    "water_cat.shape #$accodechange was 77346 features, reduced to  31662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 31662)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat = all_cat[59400:,:]\n",
    "test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74250, 31662)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74250, 8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_num = all_num[:59400,:]\n",
    "water_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = all_num[59400:,:]\n",
    "test_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to sparse matrix\n",
    "water_num = csr_matrix(water_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate \n",
    "X = hstack([water_cat, water_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten label column into a 1-D array called y\n",
    "y = np.ravel(water_labels['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### $accode - running Knn instead\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "#model = LogisticRegression(penalty = 'l2')\n",
    "#model = model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "#model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### $accode - try Knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X,y)\n",
    "#model.score(X,y) #$accode commented out this line because kernel keeps failing; from this line the code stayed the same\n",
    "#err = (y_test != est.predict(X_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78750841750841749"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create prediction accuracy function to be used in cross val\n",
    "def predict_accuracy(model, x,y):\n",
    "    y_hat = model.predict(x)\n",
    "    return np.mean(y_hat == y)\n",
    "\n",
    "# run cross validation\n",
    "score = cross_validation.cross_val_score(model, X, y, scoring = predict_accuracy).mean()\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print \"Features sorted by their score:\"\n",
    "#print sorted(zip(map(lambda x: round(x, 4), model.scores_),                 names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47520, 31670) (47520,)\n",
      "(11880, 31670) (11880,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwas \\n(47520, 77354) (47520,)\\n(11880, 77354) (11880,)\\n\\nwith no wpt_name became\\n\\n(47520, 31670) (47520,)\\n(11880, 31670) (11880,)\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train, test sets for X,Y to cross-validate, k=1 (just to verify above cross-val)\n",
    "xtrain, xtest, ytrain, ytest = \\\n",
    "cross_validation.train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "# verify shapes\n",
    "print xtrain.shape, ytrain.shape\n",
    "print xtest.shape, ytest.shape\n",
    "\n",
    "# predict labels for test set\n",
    "yhat = model.predict(xtest)\n",
    "\n",
    "# calculate accuracy\n",
    "np.mean(yhat == ytest)\n",
    "\n",
    "\"\"\"\n",
    "was \n",
    "(47520, 77354) (47520,)\n",
    "(11880, 77354) (11880,)\n",
    "\n",
    "with no wpt_name became\n",
    "\n",
    "(47520, 31670) (47520,)\n",
    "(11880, 31670) (11880,)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# prepare test data for model prediction\\ntest = pd.read_csv('./test_set_values.csv')\\n\\n#test['status_group'] = np.random.choice(range(1, 3), test.shape[0])\\ntest.drop(['id', 'wpt_name', 'subvillage'], axis=1, inplace=True)\\n\\n# make dataframe of just the categorical features\\ntest_cat = test[cat_features]\\n\\n# make dataframe of just numeric (basically, the rest of the columns)\\ntest_num = test[list(set(test.columns) - set(cat_features))]\\n\\n# replace 0s with NaN\\nfor col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\\n    test_num.loc[:,col].replace(0, np.nan, inplace = True)\\n\\n# encode categorical features w/ floats\\nfor col in cat_features:\\n    test_cat.loc[:,col] = le.transform(test_cat.loc[:,col])\\n\\n# make dummy variables\\ntest_cat = enc.transform(test_cat[cat_features])\\n\\n# impute data\\ntest_num = imp.transform(test_num)\\n\\n# standardize numeric variables\\ntest_num = preprocessing.scale(test_num)\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# prepare test data for model prediction\n",
    "test = pd.read_csv('./test_set_values.csv')\n",
    "\n",
    "#test['status_group'] = np.random.choice(range(1, 3), test.shape[0])\n",
    "test.drop(['id', 'wpt_name', 'subvillage'], axis=1, inplace=True)\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "test_cat = test[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "test_num = test[list(set(test.columns) - set(cat_features))]\n",
    "\n",
    "# replace 0s with NaN\n",
    "for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "    test_num.loc[:,col].replace(0, np.nan, inplace = True)\n",
    "\n",
    "# encode categorical features w/ floats\n",
    "for col in cat_features:\n",
    "    test_cat.loc[:,col] = le.transform(test_cat.loc[:,col])\n",
    "\n",
    "# make dummy variables\n",
    "test_cat = enc.transform(test_cat[cat_features])\n",
    "\n",
    "# impute data\n",
    "test_num = imp.transform(test_num)\n",
    "\n",
    "# standardize numeric variables\n",
    "test_num = preprocessing.scale(test_num)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to sparse matrix\n",
    "test_num = csr_matrix(test_num)\n",
    "\n",
    "# concatenate \n",
    "Xtest = hstack([test_cat, test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(Xtest)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14850"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14850"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     functional\n",
       "1                     functional\n",
       "2                     functional\n",
       "3                 non functional\n",
       "4                     functional\n",
       "5                     functional\n",
       "6                     functional\n",
       "7                 non functional\n",
       "8                 non functional\n",
       "9                     functional\n",
       "10                    functional\n",
       "11                non functional\n",
       "12                non functional\n",
       "13                non functional\n",
       "14                    functional\n",
       "15                    functional\n",
       "16                    functional\n",
       "17                    functional\n",
       "18                    functional\n",
       "19                non functional\n",
       "20                non functional\n",
       "21                    functional\n",
       "22                non functional\n",
       "23                non functional\n",
       "24                    functional\n",
       "25                    functional\n",
       "26                non functional\n",
       "27                non functional\n",
       "28       functional needs repair\n",
       "29                    functional\n",
       "                  ...           \n",
       "14820    functional needs repair\n",
       "14821                 functional\n",
       "14822    functional needs repair\n",
       "14823                 functional\n",
       "14824                 functional\n",
       "14825             non functional\n",
       "14826                 functional\n",
       "14827                 functional\n",
       "14828                 functional\n",
       "14829                 functional\n",
       "14830             non functional\n",
       "14831                 functional\n",
       "14832                 functional\n",
       "14833                 functional\n",
       "14834                 functional\n",
       "14835                 functional\n",
       "14836                 functional\n",
       "14837             non functional\n",
       "14838                 functional\n",
       "14839                 functional\n",
       "14840                 functional\n",
       "14841                 functional\n",
       "14842                 functional\n",
       "14843                 functional\n",
       "14844                 functional\n",
       "14845             non functional\n",
       "14846                 functional\n",
       "14847                 functional\n",
       "14848                 functional\n",
       "14849             non functional\n",
       "Name: status_group, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission\n",
    "\n",
    "test['status_group'] = y_hat\n",
    "\n",
    "map_dict = {0: 'functional', 1: 'non functional', 2: 'functional needs repair'}\n",
    "test['status_group'] = test['status_group'].map(map_dict)\n",
    "test['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsubmission notes:\\nKnn 1, no wptname, accuracy 7646\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_logreg = test[['id', 'status_group']]\n",
    "test_logreg.to_csv('test_knn3_noFeature_wptname.csv', index = False)\n",
    "\n",
    "\"\"\"\n",
    "submission notes:\n",
    "Knn 1, no wptname, accuracy .7646\n",
    "Knn 3, no wptname, accuracy .7855\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### random code chunks below this line #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ./test_logreg.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-5493624ce0e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test_logreg.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test_logreg2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Amigo/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Amigo/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Amigo/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Amigo/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Amigo/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File ./test_logreg.csv does not exist"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv('./test_logreg.csv')\n",
    "b = pd.read_csv('./test_logreg2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# received error that test dataset does not have as many columns as training (3dummy columns missing)\n",
    "# this is to find out which ones\n",
    "mask = np.in1d(X.columns, Xtest.columns)\n",
    "print np.where(~mask)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "water_unique = water_cat.apply(lambda x: len(x.unique()))\n",
    "print water_unique.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
