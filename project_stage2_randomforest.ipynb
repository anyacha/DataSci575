{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Numpy for working with Arrays\n",
    "import numpy as np\n",
    "# Pandas for working with data tables\n",
    "import pandas as pd\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "# Module for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Module for pretty plotting\n",
    "# import seaborn as sns\n",
    "# Module for linear regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### load data from csv files\n",
    "water_values = pd.read_csv('./data/train_set_values.csv')\n",
    "water_labels = pd.read_csv('./data/train_set_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list categorical features to be turned into dummy variables:\n",
    "cat_features = ['region_code', 'district_code', 'basin', 'region', 'public_meeting', \\\n",
    "                'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', \\\n",
    "                'management', 'payment', 'water_quality', 'quantity', \\\n",
    "                'source', 'waterpoint_type', 'date_recorded', 'recorded_by', 'funder', 'installer', \\\n",
    "               'lga', 'ward', 'scheme_name', 'management_group', 'wpt_name', 'subvillage', \\\n",
    "               'payment_type', 'quality_group', 'quantity_group', 'source_class', 'source_type', 'waterpoint_type_group']\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "water_cat = water_values[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "water_num = water_values[list(set(water_values.columns) - set(cat_features))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.py:3430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# prepare test data for model prediction\n",
    "test = pd.read_csv('./test_set_values.csv')\n",
    "\n",
    "# make test dataframe of just the categorical features\n",
    "test_cat = test[cat_features]\n",
    "\n",
    "# make test dataframe of just numeric (basically, the rest of the columns)\n",
    "test_num = test[list(set(test.columns) - set(cat_features))]\n",
    "\n",
    "# replace 0s with NaN\n",
    "for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "    test_num.loc[:,col].replace(0, np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# concatenate training and test datasets (for encoding piece)\n",
    "all_cat = pd.concat([water_cat, test_cat])\n",
    "all_num = pd.concat([water_num, test_num])\n",
    "\n",
    "# impute 'missing' for categorical NaNs\n",
    "all_cat.loc[:,'permit'][all_cat.loc[:,'permit'].isnull() == True] = 'missing'\n",
    "all_cat.loc[:,'public_meeting'][all_cat.loc[:,'public_meeting'].isnull() == True] = 'missing'\n",
    "\n",
    "\n",
    "#### I keep getting the pandas \"value trying to be set on a copy error\", even though I am using .loc[:,] to properly index\n",
    "#### No idea why ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert status labels to numeric\n",
    "water_labels['status_group'] = water_labels.status_group.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace 0s with NaN\n",
    "for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "    all_num.loc[:,col].replace(0, np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing steps\n",
    "\n",
    "# encode labels to floats\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# make dummy variables\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown = 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "# labels to floats, row by row (le doesn't work across df's)\n",
    "for col in cat_features:\n",
    "    all_cat.loc[:,col] = le.fit_transform(all_cat.loc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make dummy variables\n",
    "all_cat = enc.fit_transform(all_cat[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'gps_height', u'longitude', u'latitude', u'amount_tsh', u'num_private',\n",
       "       u'construction_year', u'id', u'population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute data\n",
    "imp = preprocessing.Imputer(missing_values='NaN', strategy='most_frequent', axis=0, verbose=0, copy=True)\n",
    "all_num = imp.fit_transform(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize numeric variables\n",
    "all_num = preprocessing.scale(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 77664)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split back into training/test now that all dummy variables have been accounted for\n",
    "water_cat = all_cat[:59400,:]\n",
    "water_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 77664)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split back into training/test now that all dummy variables have been accounted for\n",
    "test_cat = all_cat[59400:,:]\n",
    "test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74250, 77664)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74250L, 8L)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850L, 8L)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = all_num[59400:,:]\n",
    "test_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to sparse matrix\n",
    "water_num = csr_matrix(water_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate \n",
    "X = hstack([water_cat, water_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten label column into a 1-D array called y\n",
    "y = np.ravel(water_labels['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into training/test sets for crossval\n",
    "xtrain, xtest, ytrain, ytest = \\\n",
    "cross_validation.train_test_split(X, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on training\n",
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict on test\n",
    "yhats = clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81052188552188553"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy on test prediction\n",
    "np.mean(yhats == ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99997895622895627"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define adaboost\n",
    "ada = AdaBoostClassifier(clf, n_estimators=100,\n",
    "    learning_rate=1,\n",
    "    algorithm=\"SAMME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          learning_rate=1, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit adaboost\n",
    "ada.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test prediction on test (if fit to entire set, expect 1.0)\n",
    "ada_yhats = ada.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ada_yhats == ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert (real) test set to sparse matrix\n",
    "test_num = csr_matrix(test_num)\n",
    "\n",
    "# concatenate \n",
    "Xtest = hstack([test_cat, test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run prediction on (real) test\n",
    "y_hat = ada.predict(Xtest)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14850"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14850"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 non functional\n",
       "1                     functional\n",
       "2                     functional\n",
       "3                 non functional\n",
       "4                     functional\n",
       "5                     functional\n",
       "6                     functional\n",
       "7                 non functional\n",
       "8                 non functional\n",
       "9                     functional\n",
       "10                    functional\n",
       "11                non functional\n",
       "12                non functional\n",
       "13                non functional\n",
       "14                    functional\n",
       "15                    functional\n",
       "16                    functional\n",
       "17                    functional\n",
       "18                    functional\n",
       "19                non functional\n",
       "20                    functional\n",
       "21                    functional\n",
       "22                non functional\n",
       "23                non functional\n",
       "24                    functional\n",
       "25                    functional\n",
       "26                non functional\n",
       "27                non functional\n",
       "28       functional needs repair\n",
       "29                    functional\n",
       "                  ...           \n",
       "14820             non functional\n",
       "14821                 functional\n",
       "14822                 functional\n",
       "14823                 functional\n",
       "14824                 functional\n",
       "14825             non functional\n",
       "14826                 functional\n",
       "14827                 functional\n",
       "14828             non functional\n",
       "14829                 functional\n",
       "14830             non functional\n",
       "14831                 functional\n",
       "14832                 functional\n",
       "14833                 functional\n",
       "14834    functional needs repair\n",
       "14835                 functional\n",
       "14836                 functional\n",
       "14837             non functional\n",
       "14838                 functional\n",
       "14839                 functional\n",
       "14840                 functional\n",
       "14841                 functional\n",
       "14842                 functional\n",
       "14843                 functional\n",
       "14844                 functional\n",
       "14845             non functional\n",
       "14846                 functional\n",
       "14847                 functional\n",
       "14848                 functional\n",
       "14849             non functional\n",
       "Name: status_group, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission\n",
    "\n",
    "test['status_group'] = y_hat\n",
    "\n",
    "map_dict = {0: 'functional', 1: 'non functional', 2: 'functional needs repair'}\n",
    "test['status_group'] = test['status_group'].map(map_dict)\n",
    "test_submit = test[['id','status_group']]\n",
    "test_submit.to_csv('submit_adaboost.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## below code added later to produce files for ensemble. will not run properly if executed #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['ada_predict'] = y_hat\n",
    "pred_ada = test[['id', 'ada_predict']]\n",
    "pred_ada.to_csv('pred_ada.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make prediction array on water_cat to use in ensemble:\n",
    "y_ensemble = ada.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "water_values['ada_predict'] = y_ensemble\n",
    "ens_ada = water_values[['id', 'ada_predict']]\n",
    "ens_ada.to_csv('ens_ada.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### random code chunks below this line #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# received error that test dataset does not have as many columns as training (3dummy columns missing)\n",
    "# this is to find out which ones\n",
    "mask = np.in1d(X.columns, Xtest.columns)\n",
    "print np.where(~mask)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wenhong's script for sorting columns by # of uniques\n",
    "water_unique = water_cat.apply(lambda x: len(x.unique()))\n",
    "print water_unique.sort_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
