{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\pandas\\computation\\__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Numpy for working with Arrays\n",
    "import numpy as np\n",
    "# Pandas for working with data tables\n",
    "import pandas as pd\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "# Module for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Module for pretty plotting\n",
    "# import seaborn as sns\n",
    "# Module for linear regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### load data from csv files\n",
    "water_values = pd.read_csv('./data/train_set_values.csv')\n",
    "water_labels = pd.read_csv('./data/train_set_labels.csv')\n",
    "\n",
    "#water_values.drop(['wpt_name', 'subvillage'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list categorical features to be turned into dummy variables:\n",
    "cat_features = ['region_code', 'district_code', 'basin', 'region', 'public_meeting', \\\n",
    "                'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', \\\n",
    "                'management', 'payment', 'water_quality', 'quantity', \\\n",
    "                'source', 'waterpoint_type', 'date_recorded', 'recorded_by', 'funder', 'installer', \\\n",
    "               'lga', 'ward', 'scheme_name', 'management_group', 'wpt_name', 'subvillage', \\\n",
    "               'payment_type', 'quality_group', 'quantity_group', 'source_class', 'source_type', 'waterpoint_type_group']\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "water_cat = water_values[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "water_num = water_values[list(set(water_values.columns) - set(cat_features))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.py:3430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# prepare test data for model prediction\n",
    "test = pd.read_csv('./test_set_values.csv')\n",
    "\n",
    "#test['status_group'] = np.random.choice(range(1, 3), test.shape[0])\n",
    "#test.drop(['wpt_name', 'subvillage'], axis=1, inplace=True)\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "test_cat = test[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "test_num = test[list(set(test.columns) - set(cat_features))]\n",
    "\n",
    "# replace 0s with NaN\n",
    "for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "    test_num.loc[:,col].replace(0, np.nan, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cat = pd.concat([water_cat, test_cat])\n",
    "all_num = pd.concat([water_num, test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert status labels to numeric\n",
    "water_labels['status_group'] = water_labels.status_group.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace 0s with NaN\n",
    "for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "    all_num.loc[:,col].replace(0, np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing steps\n",
    "# encode labels to floats\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# make dummy variables\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown = 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.py:200: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    }
   ],
   "source": [
    "for col in cat_features:\n",
    "    all_cat.loc[:,col] = le.fit_transform(all_cat.loc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cat = enc.fit_transform(all_cat[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'gps_height', u'longitude', u'latitude', u'amount_tsh', u'num_private',\n",
       "       u'construction_year', u'id', u'population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute data\n",
    "imp = preprocessing.Imputer(missing_values='NaN', strategy='most_frequent', axis=0, verbose=0, copy=True)\n",
    "all_num = imp.fit_transform(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize numeric variables\n",
    "all_num = preprocessing.scale(all_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 92484)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_cat = all_cat[:59400,:]\n",
    "water_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 92484)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat = all_cat[59400:,:]\n",
    "test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74250, 92484)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74250L, 8L)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400L, 8L)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_num = all_num[:59400,:]\n",
    "water_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850L, 8L)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = all_num[59400:,:]\n",
    "test_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to sparse matrix\n",
    "water_num = csr_matrix(water_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate \n",
    "X = hstack([water_cat, water_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten label column into a 1-D array called y\n",
    "y = np.ravel(water_labels['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85156565656565653"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression(penalty = 'l2')\n",
    "model = model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7852525252525252"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create prediction accuracy function to be used in cross val\n",
    "def predict_accuracy(model, x,y):\n",
    "    y_hat = model.predict(x)\n",
    "    return np.mean(y_hat == y)\n",
    "\n",
    "# run cross validation\n",
    "score = cross_validation.cross_val_score(model, X, y, scoring = predict_accuracy).mean()\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47520, 92492) (47520L,)\n",
      "(11880, 92492) (11880L,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85260942760942759"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train, test sets for X,Y to cross-validate, k=1 (just to verify above cross-val)\n",
    "xtrain, xtest, ytrain, ytest = \\\n",
    "cross_validation.train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "# verify shapes\n",
    "print xtrain.shape, ytrain.shape\n",
    "print xtest.shape, ytest.shape\n",
    "\n",
    "# predict labels for test set\n",
    "yhat = model.predict(xtest)\n",
    "\n",
    "# calculate accuracy\n",
    "np.mean(yhat == ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# prepare test data for model prediction\n",
    "test = pd.read_csv('./test_set_values.csv')\n",
    "\n",
    "#test['status_group'] = np.random.choice(range(1, 3), test.shape[0])\n",
    "test.drop(['id', 'wpt_name', 'subvillage'], axis=1, inplace=True)\n",
    "\n",
    "# make dataframe of just the categorical features\n",
    "test_cat = test[cat_features]\n",
    "\n",
    "# make dataframe of just numeric (basically, the rest of the columns)\n",
    "test_num = test[list(set(test.columns) - set(cat_features))]\n",
    "\n",
    "# replace 0s with NaN\n",
    "for col in ['num_private', 'amount_tsh', 'population', 'construction_year', 'gps_height']:\n",
    "    test_num.loc[:,col].replace(0, np.nan, inplace = True)\n",
    "\n",
    "# encode categorical features w/ floats\n",
    "for col in cat_features:\n",
    "    test_cat.loc[:,col] = le.transform(test_cat.loc[:,col])\n",
    "\n",
    "# make dummy variables\n",
    "test_cat = enc.transform(test_cat[cat_features])\n",
    "\n",
    "# impute data\n",
    "test_num = imp.transform(test_num)\n",
    "\n",
    "# standardize numeric variables\n",
    "test_num = preprocessing.scale(test_num)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to sparse matrix\n",
    "test_num = csr_matrix(test_num)\n",
    "\n",
    "# concatenate \n",
    "Xtest = hstack([test_cat, test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(Xtest)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14850"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14850"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 non functional\n",
       "1                     functional\n",
       "2                 non functional\n",
       "3                 non functional\n",
       "4                     functional\n",
       "5                     functional\n",
       "6                 non functional\n",
       "7                 non functional\n",
       "8                 non functional\n",
       "9                     functional\n",
       "10                    functional\n",
       "11                non functional\n",
       "12                non functional\n",
       "13                non functional\n",
       "14                    functional\n",
       "15                    functional\n",
       "16                    functional\n",
       "17                    functional\n",
       "18                    functional\n",
       "19                non functional\n",
       "20                non functional\n",
       "21                    functional\n",
       "22                non functional\n",
       "23                non functional\n",
       "24                    functional\n",
       "25                    functional\n",
       "26                non functional\n",
       "27                non functional\n",
       "28       functional needs repair\n",
       "29                non functional\n",
       "                  ...           \n",
       "14820                 functional\n",
       "14821                 functional\n",
       "14822                 functional\n",
       "14823                 functional\n",
       "14824                 functional\n",
       "14825             non functional\n",
       "14826                 functional\n",
       "14827                 functional\n",
       "14828             non functional\n",
       "14829                 functional\n",
       "14830             non functional\n",
       "14831                 functional\n",
       "14832                 functional\n",
       "14833                 functional\n",
       "14834                 functional\n",
       "14835                 functional\n",
       "14836                 functional\n",
       "14837                 functional\n",
       "14838                 functional\n",
       "14839                 functional\n",
       "14840                 functional\n",
       "14841                 functional\n",
       "14842                 functional\n",
       "14843             non functional\n",
       "14844                 functional\n",
       "14845                 functional\n",
       "14846                 functional\n",
       "14847                 functional\n",
       "14848                 functional\n",
       "14849             non functional\n",
       "Name: status_group, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission\n",
    "\n",
    "test['status_group'] = y_hat\n",
    "\n",
    "map_dict = {0: 'functional', 1: 'non functional', 2: 'functional needs repair'}\n",
    "test['status_group'] = test['status_group'].map(map_dict)\n",
    "test['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_logreg = test[['id', 'status_group']]\n",
    "test_logreg.to_csv('test_logreg_l1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### random code chunks below this line #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv('./test_logreg.csv')\n",
    "b = pd.read_csv('./test_logreg2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# received error that test dataset does not have as many columns as training (3dummy columns missing)\n",
    "# this is to find out which ones\n",
    "mask = np.in1d(X.columns, Xtest.columns)\n",
    "print np.where(~mask)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "water_unique = water_cat.apply(lambda x: len(x.unique()))\n",
    "print water_unique.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
